{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":91657,"status":"ok","timestamp":1647050056445,"user":{"displayName":"William","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01309109182281160360"},"user_tz":-60},"id":"tjR_hF-wP6zu","outputId":"aeaa7bbd-b491-4970-8b06-385773b3ac9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pymatgen\n","  Downloading pymatgen-2022.0.17.tar.gz (40.6 MB)\n","\u001b[K     |████████████████████████████████| 40.6 MB 1.7 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting megnet\n","  Downloading megnet-1.3.0-py3-none-any.whl (114 kB)\n","\u001b[K     |████████████████████████████████| 114 kB 65.4 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.7/dist-packages (from pymatgen) (3.2.2)\n","Collecting uncertainties>=3.1.4\n","  Downloading uncertainties-3.1.6-py2.py3-none-any.whl (98 kB)\n","\u001b[K     |████████████████████████████████| 98 kB 10.2 MB/s \n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from pymatgen) (1.7.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from pymatgen) (0.8.9)\n","Collecting ruamel.yaml>=0.15.6\n","  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n","\u001b[K     |████████████████████████████████| 109 kB 72.4 MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from pymatgen) (2.6.3)\n","Collecting spglib>=1.9.9.44\n","  Downloading spglib-1.16.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n","\u001b[K     |████████████████████████████████| 292 kB 72.9 MB/s \n","\u001b[?25hRequirement already satisfied: palettable>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from pymatgen) (3.3.0)\n","Requirement already satisfied: plotly>=4.5.0 in /usr/local/lib/python3.7/dist-packages (from pymatgen) (5.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pymatgen) (2.23.0)\n","Collecting scipy>=1.5.0\n","  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n","\u001b[K     |████████████████████████████████| 38.1 MB 332 kB/s \n","\u001b[?25hCollecting monty>=3.0.2\n","  Downloading monty-2022.1.19-py3-none-any.whl (65 kB)\n","\u001b[K     |████████████████████████████████| 65 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pymatgen) (3.10.0.2)\n","Requirement already satisfied: numpy>=1.20.1 in /usr/local/lib/python3.7/dist-packages (from pymatgen) (1.21.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pymatgen) (1.3.5)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen) (3.0.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen) (1.3.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.5.0->pymatgen) (8.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.5.0->pymatgen) (1.15.0)\n","Collecting ruamel.yaml.clib>=0.2.6\n","  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n","\u001b[K     |████████████████████████████████| 546 kB 75.5 MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from uncertainties>=3.1.4->pymatgen) (0.16.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from megnet) (1.0.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pymatgen) (2018.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen) (1.24.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->megnet) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->megnet) (1.1.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->pymatgen) (1.2.1)\n","Building wheels for collected packages: pymatgen\n","  Building wheel for pymatgen (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pymatgen: filename=pymatgen-2022.0.17-cp37-cp37m-linux_x86_64.whl size=41841030 sha256=4670d3e7afc650830473e9d86bdcd26a69e79796c2d7e80ddc13ebfcfba1f9db\n","  Stored in directory: /root/.cache/pip/wheels/cf/f6/22/58a9be23c5f1b452770e02ff42047175eaf0f9c2f15219fc76\n","Successfully built pymatgen\n","Installing collected packages: ruamel.yaml.clib, uncertainties, spglib, scipy, ruamel.yaml, monty, pymatgen, megnet\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed megnet-1.3.0 monty-2022.1.19 pymatgen-2022.0.17 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 scipy-1.7.3 spglib-1.16.3 uncertainties-3.1.6\n","Mounted at /content/gdrive\n","Sat Mar 12 01:54:15 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!pip install pymatgen megnet\n","\n","import yaml\n","import json\n","import os\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tqdm import tqdm\n","\n","from pathlib import Path\n","import shutil\n","\n","from pymatgen.core.composition import Composition\n","from pymatgen.core import Structure\n","\n","from sklearn.model_selection import train_test_split\n","from megnet.models import MEGNetModel\n","from megnet.data.crystal import CrystalGraph, CrystalGraphWithBondTypes\n","from megnet.data.graph import GaussianDistance, StructureGraph\n","from megnet.data.molecule import MolecularGraph\n","from tensorflow.keras.models import load_model\n","from megnet.layers import _CUSTOM_OBJECTS\n","from megnet.models.base import GraphModel\n","import gc\n","\n","import matplotlib.pyplot as plt \n","import seaborn as sns\n","#from tensorflow import set_random_seed #bug loading this \n","\n","\n","from google import colab\n","colab.drive.mount('/content/gdrive')\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3OqIIXrdRIoJ"},"outputs":[],"source":["def read_pymatgen_dict(file):\n","    with open(file, \"r\") as f:\n","        d = json.load(f)\n","    return Structure.from_dict(d)\n","\n","\n","def energy_within_threshold(prediction, target):\n","    # compute absolute error on energy per system.\n","    # then count the no. of systems where max energy error is < 0.02.\n","    e_thresh = 0.02\n","    error_energy = tf.math.abs(target - prediction)\n","\n","    success = tf.math.count_nonzero(error_energy < e_thresh)\n","    total = tf.size(target)\n","    return success / tf.cast(total, tf.int64)\n","\n","\n","def idx_to_coords(i, j, k):\n","    if k != 1:\n","        z = 0.144826 if k == 0 else 0.355174\n","        return 0.08333333 + 0.125*i, 0.041666667 + 0.125*j, z\n","    else:\n","        return 0.041666667 + 0.125*i, 0.08333333 + 0.125*j, 0.25\n","\n","\n","################################# MODIF ICI ######################################################################\n","def prepare_dataset(dataset_path, split=None, fill_holes=True, remove_common_atoms=True, mode=\"train\"):\n","    if mode == \"train\" and split is None:\n","        raise ValueError(\"`split` argument must not be None when mode='train'\")\n","    dataset_path = Path(dataset_path)\n","    \n","    struct = {\n","        item.name.strip(\".json\"): read_pymatgen_dict(item)\n","        for item in (dataset_path / \"structures\").iterdir()\n","    }\n","\n","    data = pd.DataFrame(columns=[\"structures\"], index=struct.keys())\n","    if mode==\"train\":\n","        targets = pd.read_csv(dataset_path / \"targets.csv\", index_col=0)\n","        data = data.assign(structures=struct.values(), targets=targets)\n","    else:\n","        data = data.assign(structures=struct.values())\n","\n","    d = {\"Mo\": 42, \"W\":74, \"Se\":34, \"S\":16}\n","    if fill_holes:\n","        new_structures = []\n","        for i, struct in enumerate(data.structures):\n","            abc = np.array([[m.c, m.a, m.b] for m in struct])\n","            species = np.array([d[str(m.specie)] for m in struct])\n","            mat3d = np.histogramdd(abc, bins=(3, 8, 8), weights=species)[0]\n","            ids_holes = np.where(mat3d == 0)\n","            coords_holes = [[ax[i] for ax in ids_holes] for i in range(ids_holes[0].size)]\n","            filled_struct = struct.copy()\n","            [filled_struct.append(1, idx_to_coords(*coords)) for coords in coords_holes]\n","            new_structures.append(filled_struct)\n","        data[\"structures\"] = new_structures\n","\n","        # print(data.structure[4][:-5])\n","    if remove_common_atoms:\n","        struct_to_remove = []\n","        Mo = Composition(\"Mo\")\n","        S = Composition(\"S\")\n","        new_structures = []\n","        for i, struct in enumerate(data.structures):\n","            struct.remove_species(Mo)\n","            struct.remove_species(S)\n","            if len(struct) > 0:\n","                new_structures.append(struct)\n","            else:\n","                struct_to_remove.append(i)\n","        print(data.shape)\n","        data.drop(data.iloc[struct_to_remove].index, inplace=True)\n","        print(data.shape)\n","        data[\"structures\"] = new_structures\n","    if mode == \"train\":\n","        return data.loc[split[\"train\"]], data.loc[split[\"test\"]]\n","    else:\n","        return data\n","\n","#######################################################################################################\n","\n","def prepare_model(split,\n","    cutoff,\n","    nfeat_bond,\n","    gaussian_width,\n","    npass,\n","    nblocks,\n","    n1,\n","    n2,\n","    n3, \n","    embedding_dim,\n","    dropout,\n","    lr,\n","    output_dir,\n","    seed,\n","    prefix=''\n","    ):\n","    '''\n","    nblocks: (int) number of MEGNetLayer blocks\n","    n1: (int) number of hidden units in layer 1 in MEGNetLayer\n","    n2: (int) number of hidden units in layer 2 in MEGNetLayer\n","    n3: (int) number of hidden units in layer 3 in MEGNetLayer\n","    embedding_dim: (int) number of embedding dimension\n","    npass: (int) number of recurrent steps in Set2Set layer\n","    '''\n","\n","    model_config = {\n","      # graph params\n","      'cutoff':cutoff,\n","      'nfeat_bond':nfeat_bond,\n","      'gaussian_width':gaussian_width,\n","      # model params\n","      'npass':npass,\n","      'nblocks': nblocks,\n","      'n1': n1,\n","      'n2': n2,\n","      'n3': n3,\n","      'embedding_dim': embedding_dim,\n","      'dropout':dropout,\n","      'lr':lr,\n","      # training_params\n","      'seed':seed\n","    }\n","\n","    np.random.seed(seed)\n","    #set_random_seed(seed)\n","\n","    gaussian_centers = np.linspace(0, cutoff + 1, nfeat_bond)\n","\n","    test_name = f\"{split}_{prefix}\"\n","    for val_name, value in model_config.items():\n","      test_name += f\"{val_name}-{value}_\"\n","\n","    dirname = f\"{output_dir}/{test_name}\"\n","    if not os.path.isdir(dirname):\n","      os.mkdir(dirname)\n","    \n","    model = MEGNetModel(\n","        nblocks = nblocks,\n","        n1 = n1,\n","        n2 = n2,\n","        n3 = n3,\n","        embedding_dim = embedding_dim,\n","        graph_converter=CrystalGraph(cutoff=cutoff),\n","        centers=gaussian_centers,\n","        width=gaussian_width,\n","        loss=[\"MAE\"],\n","        npass=npass,\n","        lr=lr,\n","        metrics=energy_within_threshold,\n","    )\n","\n","    with open(f\"{dirname}/config.json\", 'w') as outfile:\n","      json.dump(model_config, outfile)\n","\n","    return model, dirname\n","\n","\n","def get_minimal_dec(struct, empty_struct):\n","  minx = 1\n","  miny = 1\n","  posx=-1\n","  posy=-1\n","  list_x = []\n","  list_y = []\n","  for dec_x in np.arange(0,8,1):\n","    new_struct = struct_augment(\n","      struct.copy(),\n","      empty_struct.copy(),\n","      dec_x = dec_x,\n","      dec_y = 0,\n","      transpose = False,\n","      rotation = 0,\n","      sandwich_flip = False\n","      )\n","    x, y, z, species = zip(*[(s.a, s.b, s.c, s.specie) for s in new_struct])\n","    size = max(x)-min(x)\n","    list_x +=[size]\n","    if size < minx :\n","      posx = dec_x\n","      minx = size\n","  for dec_y in np.arange(0,8,1):  \n","    new_struct = struct_augment(\n","      struct.copy(),\n","      empty_struct.copy(),\n","      dec_x = 0,\n","      dec_y = dec_y,\n","      transpose = False,\n","      rotation = 0,\n","      sandwich_flip = False\n","      )\n","    x, y, z, species = zip(*[(s.a, s.b, s.c, s.specie) for s in new_struct])\n","    size = max(y)-min(y)\n","    list_y +=[size]\n","    if size < miny :\n","      posy=dec_y\n","      miny=size\n","\n","  return posx, posy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YUEFOEMDZakF"},"outputs":[],"source":["with open(\"/content/gdrive/MyDrive/IDAO/IDAO_2022/splits.json\", \"r\") as f:\n","    splits = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6gaTDdVZLa7"},"outputs":[],"source":["path = \"/content/gdrive/MyDrive/IDAO/IDAO_2022\"\n","\n","shutil.unpack_archive(f\"{path}/data/dichalcogenides_public.tar.gz\", \"data\")\n","shutil.unpack_archive(f\"{path}/data/dichalcogenides_private.tar.gz\", \"data_private\")\n","targets = pd.read_csv('/content/data/dichalcogenides_public/targets.csv')\n","targets.rename(columns={\"band_gap\": \"targets\",\"_id\":\"id\"}, inplace=True)\n","data_private = prepare_dataset(\"data_private/dichalcogenides_private\", fill_holes=False, remove_common_atoms=False, mode='test')\n","\n","\n","Mo = Composition(\"Mo\")\n","S = Composition(\"S\")\n","W = Composition(\"W\")\n","Se = Composition(\"Se\")\n","struct = data_private.structures[0].copy()\n","struct.remove_species(Mo)\n","struct.remove_species(S)\n","struct.remove_species(W)\n","struct.remove_species(Se)\n","empty_struct = struct.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BViBhDO7PFQY"},"outputs":[],"source":["# get minimal pos \n","\n","if False : \n","  list_id = []\n","  list_dec_x = []\n","  list_dec_y = []\n","  for struct, id in tqdm(zip(data.structures, data.structures.index), position=0, total=data.shape[0]):\n","    x,y = get_minimal_dec(struct, empty_struct)\n","    list_id += [id]\n","    list_dec_x += [x]\n","    list_dec_y += [y]\n","  df_min_dec = pd.DataFrame({'id':list_id,'dec_x':list_dec_x,'dec_y':list_dec_y})\n","  df_min_dec.to_csv('/content/gdrive/MyDrive/IDAO/IDAO_2022/minimal_dec_public.csv',index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VD2jSfD3PFSx"},"outputs":[],"source":["df_min_dec_public = pd.read_csv('/content/gdrive/MyDrive/IDAO/IDAO_2022/minimal_dec_public.csv')\n","df_min_dec_private = pd.read_csv('/content/gdrive/MyDrive/IDAO/IDAO_2022/minimal_dec_private.csv')"]},{"cell_type":"markdown","metadata":{"id":"1JgT1F8AIZGp"},"source":["# struct augmentation / reduction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aw4I8rrnI3By"},"outputs":[],"source":["def struct_augment(\n","  struct,\n","  empty_struct,\n","  dec_x = 0,\n","  dec_y = 0,\n","  transpose = False,\n","  rotation = 0,\n","  sandwich_flip = False,\n","  mirror_x = False,\n","  mirror_y = False\n","  ):\n","  \n","  d = {\"Mo\": 42, \"W\":74, \"Se\":34, \"S\":16}\n","  Mo = Composition(\"Mo\")\n","  S = Composition(\"S\")\n","  # generate the matrix \n","  abc = np.array([[m.c, m.a, m.b] for m in struct])\n","  species = np.array([d[str(m.specie)] for m in struct])\n","  mat3d = np.histogramdd(abc, bins=(3, 8, 8), weights=species)[0]\n","  mat3d[np.where(mat3d == 0)]=1\n","\n","  # transform the matrix \n","\n","  ## periodic translation\n","  if dec_x !=0 :\n","    mat3d = np.roll(mat3d, dec_x, axis=1)\n","  if dec_y != 0 :\n","    mat3d = np.roll(mat3d, dec_y, axis=2)\n","\n","  ## transpose\n","  if transpose :\n","    mat3d = np.transpose(mat3d,(0,2,1))\n","\n","  ## rotation\n","  if rotation != 0:\n","    mat3d = np.rot90(mat3d, rotation,(1,2))\n","\n","  ## sandwich_flip\n","  if sandwich_flip:\n","    mat3d = np.rot90(mat3d, 2, (0,1))\n","\n","  # mirrors_flips \n","  if mirror_x:\n","    mat3d = np.flip(mat3d, 1)\n","  if mirror_y:\n","    mat3d = np.flip(mat3d, 2)\n","\n","  # generate the struct\n","  new_struct = empty_struct.copy()\n","  for i in range(8):\n","    for j in range(8):\n","      for k in range(3):\n","        x,y,z = idx_to_coords(i, j, k)\n","        new_struct.append(int(mat3d[k,i,j]), (x,y,z))\n","  new_struct.remove_species(Mo)\n","  new_struct.remove_species(S)\n","  return new_struct \n","\n","\n","def dataset_augment(data, df_min_dec, transposes, rotations, sandwiches, mirrors):\n","  # make an empty struct (we keep the orientation that way )\n","  Mo = Composition(\"Mo\")\n","  S = Composition(\"S\")\n","  W = Composition(\"W\")\n","  Se = Composition(\"Se\")\n","  struct = data.structures[0].copy()\n","  struct.remove_species(Mo)\n","  struct.remove_species(S)\n","  struct.remove_species(W)\n","  struct.remove_species(Se)\n","  empty_struct = struct.copy()\n","\n","  list_struct = []\n","  list_id = []\n","  list_transpose = []\n","  list_rotation = []\n","  list_sandwich = []\n","  list_mirror_x = []\n","  list_mirror_y = []\n","\n","  for struct, id in tqdm(zip(data.structures, data.structures.index), position=0, total=data.structures.shape[0]):\n","    dec_x, dec_y = df_min_dec[df_min_dec.id==id].values[0,1:]\n","\n","    for transpose in transposes:\n","      for rotation in rotations:\n","        for sandwich in sandwiches:\n","          if (int(transpose)+int((rotation==1)or(rotation==3))) == 1:\n","            new_dec_x, new_dec_y = dec_y,dec_x\n","          else :\n","            new_dec_x, new_dec_y = dec_x, dec_y\n","\n","          new_struct = struct_augment(\n","                struct.copy(),\n","                empty_struct.copy(),\n","                dec_x = new_dec_x,\n","                dec_y = new_dec_y,\n","                transpose = transpose,\n","                rotation = rotation,\n","                sandwich_flip = sandwich,\n","                mirror_x = False,\n","                mirror_y = False\n","                )\n","          list_struct += [new_struct]\n","          list_id += [id]\n","          list_transpose += [transpose]\n","          list_rotation += [rotation]\n","          list_sandwich += [sandwich]\n","          list_mirror_x += [False]\n","          list_mirror_y += [False]\n","    for mirror_x in mirrors:\n","      for mirror_y in mirrors:\n","        new_struct = struct_augment(\n","          struct.copy(),\n","          empty_struct.copy(),\n","          dec_x = dec_x,\n","          dec_y = dec_y,\n","          transpose = False,\n","          rotation = 0,\n","          sandwich_flip = False,\n","          mirror_x = mirror_x,\n","          mirror_y = mirror_y\n","        )\n","        list_struct += [new_struct]\n","        list_id += [id]\n","        list_transpose += [False]\n","        list_rotation += [0]\n","        list_sandwich += [False]\n","        list_mirror_x += [mirror_x]\n","        list_mirror_y += [mirror_y]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RLNd-G3VkJ2c"},"outputs":[],"source":["def get_results(preds,test, title='',save_path='',plot=True):\n","  ewt = energy_within_threshold(preds, test.targets.values)\n","  if plot : \n","    plt.figure(figsize=(20,10))\n","    plt.subplot(1,2,1)\n","    plt.title(f'{title} ewt : {ewt:.3f}')\n","    plt.plot([0,2],[0.02,.02],'r', alpha=.5)\n","    plt.plot([0,2],[-0.02,-0.02],'r', alpha=.5)\n","    plt.plot(test.targets,preds-test.targets,'.')\n","    plt.xlabel('Targets')\n","    plt.ylabel('Error')\n","    plt.grid()\n","    plt.subplot(1,2,2)\n","    plt.title('Error distribution')\n","    plt.grid()\n","    sns.histplot(np.abs(preds-test.targets).values)\n","    if save_path == '':\n","      plt.show()\n","    else :\n","      plt.savefig(f\"{save_path}/res.png\")\n","  return ewt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXXS_ywkQCyo"},"outputs":[],"source":["for i_split in range(10):\n","    nb_epochs = 800\n","    lr_reduce_patience = 150\n","    lr_stop_patience = 500\n","\n","    SPLIT = f\"split_{i_split}\"\n","    train, test = prepare_dataset(\"data/dichalcogenides_public\", split=splits[SPLIT], fill_holes=False, remove_common_atoms=False, mode='train')\n","    train_aug = dataset_augment(\n","      data = train,\n","      df_min_dec = df_min_dec_public,\n","      transposes = [False],\n","      rotations = [0,1,2,3],\n","      sandwiches = [False,True],\n","      mirrors = [False]\n","      )\n","    print(train_aug.shape)\n","    train_aug = train_aug.merge(targets, on=['id'])\n","    print(train_aug.shape)\n","\n","    test_aug = dataset_augment(\n","      data = test,\n","      df_min_dec = df_min_dec_public,\n","      transposes = [False],\n","      rotations = [0],\n","      sandwiches = [False],\n","      mirrors = [False]\n","      )\n","    print(test_aug.shape)\n","    test_aug = test_aug.merge(targets, on=['id'])\n","    print(test_aug.shape)\n","    \n","    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n","        monitor='energy_within_threshold',\n","        factor=0.5, \n","        verbose=1,\n","        patience=lr_reduce_patience,\n","        min_lr=0.00001\n","        )\n","    \n","    early_stopping = tf.keras.callbacks.EarlyStopping(\n","      monitor='energy_within_threshold', min_delta=0, patience=lr_stop_patience, verbose=1\n","      )\n","    \n","    model, dirname = prepare_model(split=SPLIT,\n","                                   cutoff=20,\n","                                   nfeat_bond=150,\n","                                   gaussian_width=.5,\n","                                   npass=3,\n","                                   nblocks=4,\n","                                   n1=64,\n","                                   n2=32,\n","                                   n3=32, \n","                                   embedding_dim=16,\n","                                   dropout=.2,\n","                                   lr=5e-4,\n","                                   output_dir=\"/content/gdrive/MyDrive/IDAO_2022/new_callbacks\",\n","                                   seed=42,\n","                                   prefix='rot_dwich'\n","                                   )\n","    print(dirname)\n","    model.train(train_aug.structures,\n","                train_aug.targets,\n","                validation_structures=test_aug.structures,\n","                validation_targets=test_aug.targets,\n","                epochs=nb_epochs,\n","                batch_size=128,\n","                dirname=dirname,\n","                patience=120,\n","                callbacks=[reduce_lr, early_stopping])\n","    preds = model.predict_structures(test_aug.structures)\n","    ewt = get_results(preds[:,0], test_aug, 'test', dirname, plot=True)\n","    del(model)\n","    gc.collect()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"primary_train.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}